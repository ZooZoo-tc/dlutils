# -*- coding: utf-8 -*-
"""tfrecords.version.inprogress.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19b4dWEEX1gHBRm3GvkCYq3wNCPor5CZf
"""

import tensorflow as tf
import numpy
import requests
import os.path
from os import path
from shutil import copyfile
from .utils import *

class datasets():
    def load_cifar(self):
      return tf.keras.datasets.cifar10.load_data()

class TFRecord:
  base_path = '/content/drive/My Drive/models/tfrecords/'
  # VERSIONS = Enum('V1', 'V2')

  def __init__(self,base_path=base_path,is_mount_required=True,version='V1'):
    tf.enable_eager_execution()
    self.base_path = base_path
    self.is_mount_required = is_mount_required
    self.datasets = datasets()
    self.version = version
    if is_mount_required :
      mount()

  def _bytes_feature(self,value):
    """Returns a bytes_list from a string / byte."""
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

  def _float_feature(self,value):
    """Returns a float_list from a float / double."""
    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))

  def _int64_feature(self,value):
    """Returns an int64_list from a bool / enum / int / uint."""
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

  def convert_to_tfrecords_v1(self,images, labels,fileName):
      with tf.python_io.TFRecordWriter(fileName) as writer:
        if isinstance(images[0], numpy.ndarray):
          n = images.shape[0]
          reshape = images.reshape(n, -1)
          for i in range(n):
            feature = {'image': tf.train.Feature(float_list=tf.train.FloatList(value=reshape[i])),'label': tf.train.Feature(int64_list=tf.train.Int64List(value=labels[i]))}
            example=tf.train.Example(features=tf.train.Features(feature=feature))
            writer.write(example.SerializeToString())

  def convert_to_tfrecords_v2(self,filename, data_set, label):
    """Converts a dataset to tfrecords."""
    n=len(data_set)
    if data_set.shape[0] != n:
      raise ValueError('Images size %d does not match label size %d.' %(data_set.shape[0], n))
    rows = data_set.shape[1]
    cols = data_set.shape[2]
    depth = data_set.shape[3]

    with tf.io.TFRecordWriter(filename) as writer:
      for index in range(n):
        image_raw = data_set[index].tostring()
        l=int(label[index])
        example = tf.train.Example(
            features=tf.train.Features(
                feature={'height': self._int64_feature(rows),'width': self._int64_feature(cols),'depth': self._int64_feature(depth),'label': self._int64_feature(l),'image': self._bytes_feature(image_raw)}
            )
        )
        writer.write(example.SerializeToString())

  def parser_v1(self,record,h=32,w=32,c=3,num_classes=10):
    dtype=tf.float32
    features = {'image': tf.FixedLenFeature([h * w * c], dtype),
                 'label': tf.FixedLenFeature([], tf.int64)}
    example = tf.io.parse_single_example(record, features=features)
    x, y = example["image"], example['label']
    # x = x / 255.0
    x = tf.reshape(x, [h, w, c])
    y = tf.one_hot(tf.cast(y, tf.int32), num_classes)
    return x, y

  def parser_v2(self,record,h=32,w=32,c=3,num_classes=10):
    keys_to_features = {
        "image": tf.io.FixedLenFeature([], tf.string),
        "label": tf.io.FixedLenFeature([], tf.int64),
        "height": tf.io.FixedLenFeature([], tf.int64),
        "width": tf.io.FixedLenFeature([], tf.int64),
        "depth": tf.io.FixedLenFeature([], tf.int64)
    }
    parsed = tf.io.parse_single_example(record, keys_to_features)
    parsed_image = tf.io.decode_raw(parsed["image"], tf.uint8)
    parsed_image = tf.cast(parsed_image, tf.float32) / 255.0
    parsed_image =  tf.reshape(parsed_image, [h, w, c])
    # parsed_image = tf.image.per_image_standardization(parsed_image) ????? per image standarization -- should we use or not
    
    # label = tf.cast(parsed["label"], tf.int32)
    label = tf.one_hot(tf.cast(parsed["label"], tf.int32), num_classes)
    return parsed_image, label

  def load_cifar10(self):
      cifar10_tfrecord_path = self.base_path+'cifar10/'
      if self.version == 'V1':
          cifar10_tfrecord_path = os.path.join(cifar10_tfrecord_path+'v1/')
      elif self.version == 'V2':
          cifar10_tfrecord_path = os.path.join(cifar10_tfrecord_path+'v2/')

      mkdirs(cifar10_tfrecord_path)
      train_tf_record_filepath = cifar10_tfrecord_path+'train.tfrecords'
      test_tf_record_filepath = cifar10_tfrecord_path+'test.tfrecords'
      # class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

      if is_file_exists(train_tf_record_filepath) == False:      
          (x_train, y_train), (x_test, y_test) = self.datasets.load_cifar()
          
          if self.version == 'V1':
            self.convert_to_tfrecords_v1(x_train,y_train,'train.tfrecords')
            self.convert_to_tfrecords_v1(x_test,y_test,'test.tfrecords')
          elif self.version == 'V2':
            self.convert_to_tfrecords_v2('train.tfrecords',x_train, y_train)
            self.convert_to_tfrecords_v2('test.tfrecords',x_test, y_test)

          copyfile('train.tfrecords', train_tf_record_filepath)
          os.remove('train.tfrecords')
          copyfile('test.tfrecords', test_tf_record_filepath)
          os.remove('test.tfrecords')
      return (train_tf_record_filepath,test_tf_record_filepath)

# (train_tf_record_filepath,test_tf_record_filepath) = TFRecord(version="V2").load_cifar10()
# print(train_tf_record_filepath,'---',test_tf_record_filepath)